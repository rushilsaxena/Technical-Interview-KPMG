{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"Over, 600,000 accounts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structuring\n",
    "\n",
    "data.columns = [i.lower() for i in data.columns]\n",
    "data.customer_name = data.customer_name.str.lower()\n",
    "data.address = data.address.str.lower()\n",
    "data.another_personal_info = data.another_personal_info.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistent Data\n",
    "\n",
    "data['customer_name'] = data.customer_name.str.replace('org','organization')\n",
    "data['customer_name'] = data.customer_name.str.replace('#','')\n",
    "data['customer_name'] = data.customer_name.str.replace(':','')\n",
    "\n",
    "data['address'] = data.address.str.replace('Postal Code','pc')\n",
    "data['address'] = data.address.str.replace('post code','pc')\n",
    "\n",
    "data['another_personal_info'] = data.another_personal_info.str.replace('(','')\n",
    "data['another_personal_info'] = data.another_personal_info.str.replace(')','')\n",
    "data['another_personal_info'] = data.another_personal_info.str.replace(' ','')\n",
    "data['another_personal_info'] = data['another_personal_info'].str[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['address_info'] = data.latitude.astype(str)+ \" & \" + data.longitude.astype(str)\n",
    "key = 'primary_key'\n",
    "col1 = 'contact_info'\n",
    "col2 = 'address_info'\n",
    "\n",
    "# LD features and Missing features \n",
    "unique = data.dropna(subset=[col1, col2], how='all').drop_duplicates([col1,col2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_df = pd.DataFrame()\n",
    "data_temp = data[[key, col1, col2]].copy()\n",
    "data_temp.fillna('missing',inplace=True)\n",
    "\n",
    "for i in tqdm(unique[key]):\n",
    "    col1_value = data_temp.loc[data_temp[key]==i, col1].values[0]\n",
    "    col2_value = data_temp.loc[data_temp[key]==i, col2].values[0]\n",
    "    duplicate_ids = data_temp.loc[(data_temp[col2]==col2_value)\n",
    "                                  &(data_temp[col1]==col1_value)\n",
    "                                  &(data_temp[key]!=i), \n",
    "                                  key].values.tolist()\n",
    "    if duplicate_ids:\n",
    "        dup_match = [(i, dup_id) for dup_id in duplicate_ids]\n",
    "        dup_df = dup_df.append(pd.DataFrame(dup_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_ratio_and_distance(s, t, ratio_calc = True):\n",
    "    # Initialize matrix of zeros\n",
    "    try:\n",
    "        rows = len(s)+1\n",
    "        cols = len(t)+1\n",
    "        distance = np.zeros((rows,cols),dtype = int)\n",
    "        # Populate matrix of zeros with the indeces of each character of both strings\n",
    "        for i in range(1, rows):\n",
    "            for k in range(1,cols):\n",
    "                distance[i][0] = i\n",
    "                distance[0][k] = k\n",
    "        # Iterate over the matrix to compute the cost of deletions,insertions and/or substitutions    \n",
    "        for col in range(1, cols):\n",
    "            for row in range(1, rows):\n",
    "                if s[row-1] == t[col-1]:\n",
    "                    cost = 0 # If the characters are the same in the two strings in a given position [i,j] then the cost is 0\n",
    "                else:\n",
    "                    # In order to align the results with those of the Python Levenshtein package, if we choose to calculate the ratio\n",
    "                    # the cost of a substitution is 2. If we calculate just distance, then the cost of a substitution is 1.\n",
    "                    if ratio_calc == True:\n",
    "                        cost = 2\n",
    "                    else:\n",
    "                        cost = 1\n",
    "                distance[row][col] = min(distance[row-1][col] + 1,      # Cost of deletions\n",
    "                                     distance[row][col-1] + 1,          # Cost of insertions\n",
    "                                     distance[row-1][col-1] + cost)     # Cost of substitutions\n",
    "        if ratio_calc == True:\n",
    "            # Computation of the Levenshtein Distance Ratio\n",
    "            Ratio = ((len(s)+len(t)) - distance[row][col]) / (len(s)+len(t))\n",
    "            return Ratio\n",
    "        else:\n",
    "            # print(distance) # Uncomment if you want to see the matrix showing how the algorithm computes the cost of deletions,\n",
    "            # insertions and/or substitutions\n",
    "            # This is the minimum number of edits needed to convert string a to string b\n",
    "            return \"The strings are {} edits away\".format(distance[row][col])\n",
    "    except:\n",
    "        return '''Levenshtine Distance couldn't be calculated'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 'customer_name,address,another_personal_info,another_personal_info,another_personal_info,another_personal_info,another_personal_info'.split(\",\")\n",
    "dup_df.columns = [key, \"Dup_\"+key]\n",
    "dup_match = pd.merge(dup_df, data[cols+[key]], on=key, how='left')\n",
    "df = pd.merge(dup_match, data[cols+[key]], left_on=\"Dup_\"+ key, right_on=key, how='left')\n",
    "all_cols = df.columns.tolist()\n",
    "all_cols.sort()\n",
    "df = df[all_cols].drop('Dup_partyid',1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df['address'] = df.apply(lambda x: levenshtein_ratio_and_distance(x['address_x'], x['address_y']), axis=1)\n",
    "df['LD_email_address'] = df.apply(lambda x: levenshtein_ratio_and_distance(x['another_personal_info_x'], x['another_personal_info_y']), axis=1)\n",
    "df['LD_another_personal_info'] = df.apply(lambda x: levenshtein_ratio_and_distance(x['another_personal_info_x'], x['another_personal_info_y']), axis=1)\n",
    "df['LD_another_personal_info'] = df.apply(lambda x: levenshtein_ratio_and_distance(x['another_personal_info_x'], x['another_personal_info_y']), axis=1)\n",
    "df['id_match'] = 0\n",
    "df.loc[df.id_x == df.id_y, 'id_match'] = 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['primary_key_x', 'primary_key_y','account_info_x','account_info_y', 'LD_id_info',\n",
    "         'other_id_x','other_id_y', 'other_id_match','customer_name_x', 'customer_name_y', \n",
    "         'LD_customer_name', 'address_x', 'address_y','LD_address', 'another_personal_info_x', \n",
    "         'another_personal_info_y','LD_another_personal_info', 'another_personal_info_x',\n",
    "         'another_personal_info_y', 'address_info_x', 'address_info_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['another_personal_info_missing'] = 0 \n",
    "df.loc[(df.another_personal_info_x.isna())|(df.another_personal_info_y.isna()),'another_personal_info_missing'] = 1\n",
    "df.loc[(df.another_personal_info_x.isna())&(df.another_personal_info_y.isna()),'another_personal_info_missing'] = 2\n",
    "df['another_personal_info_missing'] = 0 \n",
    "df.loc[(df.primarycontactname_x.isna())|(df.primarycontactname_y.isna()),'another_personal_info_missing'] = 1\n",
    "df.loc[(df.primarycontactname_x.isna())&(df.primarycontactname_y.isna()),'another_personal_info_missing'] = 2\n",
    "df['another_personal_info_missing'] = 0 \n",
    "df.loc[(df.formattedphonenumber_x.isna())|(df.formattedphonenumber_y.isna()),'another_personal_info_missing'] = 1\n",
    "df.loc[(df.formattedphonenumber_x.isna())&(df.formattedphonenumber_y.isna()),'another_personal_info_missing'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('duplicate_data.xlsx', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
